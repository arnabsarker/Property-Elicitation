{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from classifiers import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = 'datasets/mnist_train.csv'\n",
    "test_path = 'datasets/mnist_test.csv'\n",
    "y_col = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features_and_labels(dataset, y_col):\n",
    "    y = dataset[:, y_col:y_col+1]\n",
    "    selector = [col for col in range(dataset.shape[1]) if col != y_col]\n",
    "    X = dataset[:, selector]\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import data and get sets\n",
    "train_set = np.genfromtxt(train_path, delimiter=',')\n",
    "test_set = np.genfromtxt(test_path, delimiter=',')\n",
    "\n",
    "train_X, train_y = get_features_and_labels(train_set, y_col)\n",
    "test_X, test_y = get_features_and_labels(test_set, y_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Truncate datasets/mess around with them as needed\n",
    "n = 1000\n",
    "train_X, train_y = train_X[0:n, :], train_y[0:n, :]\n",
    "test_X, test_y = test_X[0:n, :], test_y[0:n, :]\n",
    "\n",
    "#Normalize Data\n",
    "train_X, train_y = train_X - np.mean(train_X) , train_y\n",
    "test_X, test_y = test_X - np.mean(test_X) , test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = test_y.size\n",
    "train_y = train_y.astype(int)\n",
    "test_y = test_y.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Quantile Regression \n",
    "Learning $3 \\lg k$ quantiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_absolute_loss(u, y, alpha):\n",
    "    y = np.array(y.T[0]) ## y is given as a column matrix, but predictions are not\n",
    "    zs = np.zeros_like(y)\n",
    "    return np.mean((1 - alpha) * np.maximum((u - y), zs) + alpha * np.maximum((y - u), zs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mode(array):\n",
    "    most = max(list(map(array.count, array)))\n",
    "    return list(set(filter(lambda x: array.count(x) == most, array)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted Loss of LogisticQuantileAT, gamma=0.1111111111111111 0.4457777777777777\n",
      "0-1 Loss of LogisticQuantileAT, gamma=0.1111111111111111 0.802\n",
      "Weighted Loss of LogisticQuantileAT, gamma=0.2222222222222222 0.6322222222222221\n",
      "0-1 Loss of LogisticQuantileAT, gamma=0.2222222222222222 0.78\n",
      "Weighted Loss of LogisticQuantileAT, gamma=0.3333333333333333 0.7686666666666667\n",
      "0-1 Loss of LogisticQuantileAT, gamma=0.3333333333333333 0.7969999999999999\n",
      "Weighted Loss of LogisticQuantileAT, gamma=0.4444444444444444 0.8154444444444444\n",
      "0-1 Loss of LogisticQuantileAT, gamma=0.4444444444444444 0.794\n",
      "Weighted Loss of LogisticQuantileAT, gamma=0.5555555555555556 0.8216666666666668\n",
      "0-1 Loss of LogisticQuantileAT, gamma=0.5555555555555556 0.8109999999999999\n",
      "Weighted Loss of LogisticQuantileAT, gamma=0.6666666666666666 0.7786666666666667\n",
      "0-1 Loss of LogisticQuantileAT, gamma=0.6666666666666666 0.839\n",
      "Weighted Loss of LogisticQuantileAT, gamma=0.7777777777777778 0.665\n",
      "0-1 Loss of LogisticQuantileAT, gamma=0.7777777777777778 0.834\n",
      "Weighted Loss of LogisticQuantileAT, gamma=0.8888888888888888 0.4601111111111112\n",
      "0-1 Loss of LogisticQuantileAT, gamma=0.8888888888888888 0.833\n"
     ]
    }
   ],
   "source": [
    "ATs = []\n",
    "AT_predictions = []\n",
    "s = int(3 * np.log2(np.unique(train_y).size)) # Number of quantiles\n",
    "for i in range(1, s):\n",
    "    a = i/s\n",
    "\n",
    "    clf6 = QuantileAT(gamma=a, alpha=1., kernel_type='linear', kernel_param=1, loss_function='logistic')\n",
    "    clf6.fit(train_X, train_y)\n",
    "    ATpredictions = clf6.predict(test_X)\n",
    "    print('Weighted Loss of QuantileAT, gamma=' + str(a) + ' %s' %\n",
    "          weighted_absolute_loss(ATpredictions, test_y, a))\n",
    "    print('0-1 Loss of QuantileAT, gamma=' + str(a) + ' %s' %\n",
    "          metrics.zero_one_loss(ATpredictions, test_y))\n",
    "    ATs.append(clf6)\n",
    "    AT_predictions.append(ATpredictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.808"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AT_preds = np.zeros((n, s))\n",
    "for i in range(1, s):\n",
    "    AT_preds[:, i] = AT_predictions[i - 1]\n",
    "AT_preds = AT_preds.astype(int)\n",
    "quantile_predictions = np.zeros((n, 1))\n",
    "\n",
    "for i in range(1, n):\n",
    "    quantiles = AT_preds[i, :]\n",
    "    quantile_predictions[i, :] = np.random.choice(mode(quantiles.tolist()))\n",
    "    \n",
    "metrics.zero_one_loss(quantile_predictions, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted Loss of LogisticQuantileAT, gamma=0.1111111111111111 0.4546666666666666\n",
      "0-1 Loss of LogisticQuantileAT, gamma=0.1111111111111111 0.874\n",
      "Weighted Loss of LogisticQuantileAT, gamma=0.2222222222222222 0.8131111111111111\n",
      "0-1 Loss of LogisticQuantileAT, gamma=0.2222222222222222 0.884\n",
      "Weighted Loss of LogisticQuantileAT, gamma=0.3333333333333333 1.0716666666666665\n",
      "0-1 Loss of LogisticQuantileAT, gamma=0.3333333333333333 0.884\n",
      "Weighted Loss of LogisticQuantileAT, gamma=0.4444444444444444 1.2127777777777777\n",
      "0-1 Loss of LogisticQuantileAT, gamma=0.4444444444444444 0.893\n",
      "Weighted Loss of LogisticQuantileAT, gamma=0.5555555555555556 1.3025555555555557\n",
      "0-1 Loss of LogisticQuantileAT, gamma=0.5555555555555556 0.913\n",
      "Weighted Loss of LogisticQuantileAT, gamma=0.6666666666666666 1.1523333333333332\n",
      "0-1 Loss of LogisticQuantileAT, gamma=0.6666666666666666 0.913\n",
      "Weighted Loss of LogisticQuantileAT, gamma=0.7777777777777778 0.871\n",
      "0-1 Loss of LogisticQuantileAT, gamma=0.7777777777777778 0.901\n",
      "Weighted Loss of LogisticQuantileAT, gamma=0.8888888888888888 0.5740000000000002\n",
      "0-1 Loss of LogisticQuantileAT, gamma=0.8888888888888888 0.901\n"
     ]
    }
   ],
   "source": [
    "ATs = []\n",
    "AT_predictions = []\n",
    "s = int(3 * np.log2(np.unique(train_y).size)) # Number of quantiles\n",
    "for i in range(1, s):\n",
    "    a = i/s\n",
    "\n",
    "    clf6 = QuantileAT(gamma=a, alpha=1., kernel_type='rbf', kernel_param=1, loss_function='logistic')\n",
    "    clf6.fit(train_X, train_y)\n",
    "    ATpredictions = clf6.predict(test_X)\n",
    "    print('Weighted Loss of QuantileAT, gamma=' + str(a) + ' %s' %\n",
    "          weighted_absolute_loss(ATpredictions, test_y, a))\n",
    "    print('0-1 Loss of QuantileAT, gamma=' + str(a) + ' %s' %\n",
    "          metrics.zero_one_loss(ATpredictions, test_y))\n",
    "    ATs.append(clf6)\n",
    "    AT_predictions.append(ATpredictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.902"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AT_preds = np.zeros((n, s))\n",
    "for i in range(1, s):\n",
    "    AT_preds[:, i] = AT_predictions[i - 1]\n",
    "AT_preds = AT_preds.astype(int)\n",
    "quantile_predictions = np.zeros((n, 1))\n",
    "\n",
    "for i in range(1, n):\n",
    "    quantiles = AT_preds[i, :]\n",
    "    quantile_predictions[i, :] = np.random.choice(mode(quantiles.tolist()))\n",
    "    \n",
    "metrics.zero_one_loss(quantile_predictions, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Multiclass Algorithms (for Comparison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.18100000000000005"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Standard Logisitic regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression(random_state=0, solver='lbfgs', multi_class='multinomial').fit(train_X, train_y)\n",
    "metrics.zero_one_loss(clf.predict(test_X), test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
