{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from classifiers import *\n",
    "from timeit import default_timer as timer\n",
    "from cross_validation import *\n",
    "import data_storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5]\n",
      "Cross Validating parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0.5: {'AT': <DictProxy object, typeid 'dict' at 0x1a18770860>, 'IT': <DictProxy object, typeid 'dict' at 0x1a18770f60>}}\n",
      "0.525\n",
      "0.425\n",
      "0.525\n",
      "0.425\n",
      "0.425\n",
      "0.525\n",
      "0.525\n",
      "0.4\n",
      "0.475\n",
      "0.475\n",
      "{'0.0001_1e-06': 2.375, '1_1e-06': 2.35}\n",
      "1_1e-06\n",
      "{'AT': {0.5: {'reg': 1.0, 'kernel': 1e-06}}, 'IT': {0.5: {'reg': 0.0001, 'kernel': 1e-06}}}\n",
      "[0.5]\n",
      "[1.0]\n",
      "[1e-06]\n"
     ]
    }
   ],
   "source": [
    "def log(string, style='a'):\n",
    "    print(string)\n",
    "    global dataset_name\n",
    "    file_name = dataset_name + '_log.txt'\n",
    "    with open(file_name, style) as file:\n",
    "        file.write(str(string) + '\\n')\n",
    "        \n",
    "\n",
    "k = 5\n",
    "data_storage.init(k)\n",
    "classes = np.arange(k)\n",
    "\n",
    "dataset_name = 'SimplexTesting'\n",
    "\n",
    "surrogate = 'AT'\n",
    "\n",
    "\n",
    "num_quantiles = 1 # int(round(5 * np.log10(k)))\n",
    "gammas= [1.0 * i / (num_quantiles + 1) for i in range(1, num_quantiles + 1)]\n",
    "log(gammas)\n",
    "\n",
    "kernel_type = 'linear'\n",
    "loss_function = 'logistic'\n",
    "\n",
    "opt_type = 'SciPy'\n",
    "opt_params = {'learning_rate': 1e-6, 'momentum_gamma': 0.9, 'batch_size': 100}\n",
    "\n",
    "\n",
    "log('Cross Validating parameters')\n",
    "cv_dir_name_base = 'cv_' + dataset_name\n",
    "kernel_params = [1e-6]\n",
    "reg_params = [1e-4, 1]\n",
    "\n",
    "best_parameters = cross_validate_large_kernel_grid(surrogate, kernel_type, kernel_params, reg_params, data_storage.X_train, data_storage.y_train, classes,\n",
    "                                             gammas, loss_function, opt_type, opt_params, cv_dir_name_base)\n",
    "\n",
    "log(best_parameters)\n",
    "with open(dataset_name + '_cv_parameter_dict.csv', 'w') as csv_file:\n",
    "    writer = csv.writer(csv_file)\n",
    "    for key, value in best_parameters.items():\n",
    "        writer.writerow([key, value])\n",
    "\n",
    "(gammas, alphas, kernel_params) = get_params(best_parameters, surrogate)\n",
    "\n",
    "log(gammas)\n",
    "log(alphas)\n",
    "log(kernel_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = 'datasets/mnist_train.csv'\n",
    "test_path = 'datasets/mnist_test.csv'\n",
    "y_col = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features_and_labels(dataset, y_col):\n",
    "    y = dataset[:, y_col:y_col+1]\n",
    "    selector = [col for col in range(dataset.shape[1]) if col != y_col]\n",
    "    X = dataset[:, selector]\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import data and get sets\n",
    "train_set = np.genfromtxt(train_path, delimiter=',')\n",
    "test_set = np.genfromtxt(test_path, delimiter=',')\n",
    "\n",
    "train_X, train_y = get_features_and_labels(train_set, y_col)\n",
    "test_X, test_y = get_features_and_labels(test_set, y_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Truncate datasets/mess around with them as needed\n",
    "n = 1000\n",
    "train_X, train_y = train_X[0:n, :], train_y[0:n, :]\n",
    "test_X, test_y = test_X[0:n, :], test_y[0:n, :]\n",
    "\n",
    "#Normalize Data\n",
    "train_X, train_y = train_X - np.mean(train_X) , train_y\n",
    "test_X, test_y = test_X - np.mean(test_X) , test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = test_y.size\n",
    "train_y = train_y.astype(int)\n",
    "test_y = test_y.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Quantile Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_classifiers(X_train, y_train, X_test, y_test, a, reg_param=1,\n",
    "                      kernel='linear', kernel_param=1, loss_function='logistic',\n",
    "                      opt_type='SGD', opt_params={'learning_rate': 1}):\n",
    "    results = {}\n",
    "    \n",
    "    base = opt_params['plot_file']\n",
    "    opt_params['plot_file'] = 'IT' + base\n",
    "    start = timer()\n",
    "    clf5 = QuantileIT(gamma=a, alpha=reg_param, kernel_type=kernel, opt_type=opt_type, opt_params=opt_params,\n",
    "                              kernel_param=kernel_param, loss_function=loss_function)\n",
    "    clf5.fit(X_train, y_train)\n",
    "    preds_5 = clf5.predict(X_test)\n",
    "    end = timer()\n",
    "    \n",
    "    abs_loss = weighted_absolute_loss(preds_5, y_test, a)\n",
    "    print('Weighted Absolute Loss of QuantileIT, gamma=' + str(a) + ' %s' %\n",
    "          abs_loss)\n",
    "    \n",
    "    preds_5_in = clf5.predict(X_train)\n",
    "    abs_loss_in = weighted_absolute_loss(preds_5_in, y_train, a)\n",
    "    print('In Sample Weighted Absolute Loss of QuantileIT, gamma=' + str(a) + ' %s' %\n",
    "          abs_loss_in)\n",
    "    print('Time Elapsed: ' + str(end - start))\n",
    "    \n",
    "    results[clf5] = {'AbsLoss': abs_loss, 'Preds': preds_5}\n",
    "    \n",
    "    print(' ')\n",
    "\n",
    "    opt_params['plot_file'] = 'AT' + base\n",
    "    start = timer()\n",
    "    clf6 = QuantileAT(gamma=a, alpha=reg_param, kernel_type=kernel, opt_type=opt_type, opt_params=opt_params,\n",
    "                              kernel_param=kernel_param, loss_function=loss_function)\n",
    "    clf6.fit(X_train, y_train)\n",
    "    preds_6 = clf6.predict(X_test)\n",
    "    end = timer()\n",
    "    abs_loss = weighted_absolute_loss(preds_6, y_test, a)\n",
    "    print('Weighted Absolute Loss of QuantileAT, gamma=' + str(a) + ' %s' %\n",
    "          abs_loss)\n",
    "    \n",
    "    preds_6_in = clf6.predict(X_train)\n",
    "    print('In Sample Weighted Absolute Loss of QuantileAT, gamma=' + str(a) + ' %s' %\n",
    "          abs_loss_in)\n",
    "    print('Time Elapsed: ' + str(end - start))\n",
    "    \n",
    "    results[clf6] = {'AbsLoss': abs_loss, 'Preds': preds_6}\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = 10\n",
    "kern = 'linear'\n",
    "kern_param = 1\n",
    "lf = 'hinge'\n",
    "\n",
    "parms = {'learning_rate': 0.00000001, 'momentum_gamma': 0.9,\n",
    "         'batch_size': 500, 'plot_file': 'test.png'}\n",
    "\n",
    "results = train_classifiers(train_X, train_y, test_X, test_y, 0.3, reg_param=reg,\n",
    "                            kernel=kern, kernel_param=kern_param, loss_function=lf,\n",
    "                            opt_type='SGD', opt_params=parms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Multiclass Test\n",
    "Learning $3 \\lg k$ quantiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surrogate='AT'\n",
    "num_quantiles = 5\n",
    "gammas= [i / (num_quantiles + 1) for i in range(1, num_quantiles + 1)]\n",
    "alphas=[1000, 100, 10, 10, 1000]\n",
    "kernel_type='linear'\n",
    "kernel_param = 10\n",
    "loss_function='hinge'\n",
    "opt_type = 'Momentum'\n",
    "opt_params={'learning_rate': 1e-8, 'momentum_gamma': 0.9, 'batch_size': 100}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = QuantileMulticlass(surrogate=surrogate, gammas=gammas, alphas=alphas, \n",
    "                         kernel_type=kernel_type, kernel_param=kernel_param, loss_function=loss_function, \n",
    "                         opt_type=opt_type, opt_params=opt_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = clf.predict_score(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_vote = clf.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(weighted_absolute_loss(preds, test_y, 0.5))\n",
    "print(weighted_absolute_loss(preds_vote, test_y, 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(zo_loss(preds, test_y))\n",
    "print(zo_loss(preds_vote, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.concatenate((preds, test_y), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surrogate='IT'\n",
    "num_quantiles = 5\n",
    "gammas= [i / (num_quantiles + 1) for i in range(1, num_quantiles + 1)]\n",
    "alphas=[1, 1000, 1000, 1, 10]\n",
    "kernel_type='linear'\n",
    "kernel_param = 10\n",
    "loss_function='hinge'\n",
    "opt_type = 'Momentum'\n",
    "opt_params={'learning_rate': 1e-8, 'momentum_gamma': 0.9, 'batch_size': 100}\n",
    "\n",
    "clf = QuantileMulticlass(surrogate=surrogate, gammas=gammas, alphas=alphas, \n",
    "                         kernel_type=kernel_type, kernel_param=kernel_param, loss_function=loss_function, \n",
    "                         opt_type=opt_type, opt_params=opt_params)\n",
    "\n",
    "clf.fit(train_X, train_y)\n",
    "\n",
    "preds = clf.predict_score(test_X)\n",
    "\n",
    "preds_vote = clf.predict(test_X)\n",
    "\n",
    "print(weighted_absolute_loss(preds, test_y, 0.5))\n",
    "print(weighted_absolute_loss(preds_vote, test_y, 0.5))\n",
    "\n",
    "print(zo_loss(preds, test_y))\n",
    "print(zo_loss(preds_vote, test_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Multiclass Algorithms (for Comparison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Logisitic regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "clf_log = LogisticRegression(random_state=0, solver='lbfgs', multi_class='multinomial', fit_intercept=False).fit(train_X, train_y)\n",
    "metrics.zero_one_loss(clf_log.predict(test_X), test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_absolute_loss(clf_log.predict(test_X), test_y, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
